{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krishna\\engineproject\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cachetools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5fc5b37c68fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLightFM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcachetools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcachedmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLRUCache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcachetools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cachetools'"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sparsity as sp\n",
    "from scipy import sparse\n",
    "from lightfm import LightFM\n",
    "from cachetools import cachedmethod, LRUCache\n",
    "from cachetools.keys import hashkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFMRecommender(LightFM):\n",
    "    \n",
    "    \n",
    "    def __init__(self, indicators='both', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.uid_map = pd.Series([])\n",
    "        self.iid_map = pd.Series([])\n",
    "        if indicators in ['both', 'users', 'items', False]:\n",
    "            self.indicator_setting = indicators\n",
    "        elif indicators:\n",
    "            self.indicator_setting = 'both'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid identity_matrix parameters: {}\"\n",
    "                             .format(indicators))\n",
    "        self.user_feature_names = pd.Index([])\n",
    "        self.item_feature_names = pd.Index([])\n",
    "        self.baseline = pd.Series([])\n",
    "        self._user_indicator = None\n",
    "        self._item_indicator = None\n",
    "        self._item_cache = LRUCache(maxsize=8)\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit_partial(self, interactions: sp.SparseFrame,\n",
    "                    user_features: sp.SparseFrame = None,\n",
    "                    item_features: sp.SparseFrame = None,\n",
    "                    sample_weight=None,\n",
    "                    epochs=1,\n",
    "                    num_threads=1,\n",
    "                    verbose=False):\n",
    "        try:\n",
    "            self._check_initialized()\n",
    "        except ValueError:\n",
    "            self.prepare(interactions, item_features, user_features)\n",
    "\n",
    "        interactions = interactions.data\n",
    "        user_features = getattr(user_features, 'data', None)\n",
    "        item_features = getattr(item_features, 'data', None)\n",
    "\n",
    "        user_features, item_features = self.append_indicators(\n",
    "            user_features, item_features\n",
    "        )\n",
    "\n",
    "        super().fit_partial(interactions, user_features, item_features,\n",
    "                            sample_weight, epochs, num_threads, verbose)\n",
    "\n",
    "        \n",
    "        \n",
    "    def prepare(self, interactions, item_features, user_features):\n",
    "        \n",
    "        self.uid_map = pd.Series(np.arange(interactions.shape[0]),\n",
    "                                 index=interactions.index)\n",
    "\n",
    "        # TODO fix part where interactions are created with MultiIndex in cols\n",
    "        if isinstance(interactions.columns, pd.MultiIndex):\n",
    "            interactions._columns = interactions.columns.levels[0]\n",
    "\n",
    "        self.iid_map = pd.Series(np.arange(interactions.shape[1]),\n",
    "                                 index=interactions.columns)\n",
    "        if self.indicator_setting:\n",
    "            self._init_indicators()\n",
    "        if not self.indicator_setting and \\\n",
    "                (user_features is None or item_features is None):\n",
    "            raise ValueError(\"Can't estimate embeddings without indicators. \"\n",
    "                             \"Try setting identity_matrix='both' or pass user \"\n",
    "                             \"and item features to estimate embeddings.\")\n",
    "\n",
    "        self.user_feature_names = getattr(user_features, 'columns', None)\n",
    "        self.item_feature_names = getattr(item_features, 'columns', None)\n",
    "\n",
    "        self.baseline = pd.Series(\n",
    "            np.asarray(interactions.mean(axis=0)).flatten(),\n",
    "            index=interactions.columns,\n",
    "            name='score') \\\n",
    "            .sort_values(ascending=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def append_indicators(self, user_features, item_features):\n",
    "        \n",
    "        if self.indicator_setting in ['users', 'both']:\n",
    "            if user_features is not None:\n",
    "                user_features = sparse.hstack([user_features,\n",
    "                                               self._user_indicator[:-1, :]])\n",
    "            else:\n",
    "                user_features = self._user_indicator[:-1, :]\n",
    "        if self.indicator_setting in ['items', 'both']:\n",
    "            if item_features is not None:\n",
    "                item_features = sparse.hstack([item_features,\n",
    "                                               self._item_indicator])\n",
    "            else:\n",
    "                item_features = self._item_indicator\n",
    "        return user_features, item_features\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _init_indicators(self):\n",
    "        \"\"\"Initialize indicator matrices.\"\"\"\n",
    "        if self.indicator_setting in ['both', 'users']:\n",
    "            D = len(self.uid_map)\n",
    "            self._user_indicator = sparse.vstack([\n",
    "                sparse.identity(D, format='csr'),\n",
    "                sparse.csr_matrix((1, D))\n",
    "            ])\n",
    "        if self.indicator_setting in ['items', 'both']:\n",
    "            self._item_indicator = sparse.identity(\n",
    "                len(self.iid_map), format='csr')\n",
    "\n",
    "            \n",
    "    def append_user_identity_row(self, v, idx):\n",
    "        return sparse.hstack([v, self._user_indicator[idx, :]])\n",
    "    \n",
    "    \n",
    "    def _check_missing_features(self, item_feat, user_feat):\n",
    "        if user_feat is not None:\n",
    "            user_feat_diff = set(self.user_feature_names) - \\\n",
    "                                set(user_feat.columns)\n",
    "            if len(user_feat_diff):\n",
    "                raise ValueError('Missing user features: {}'\n",
    "                                 .format(user_feat_diff))\n",
    "\n",
    "        if item_feat is not None and self.user_feature_names is not None:\n",
    "            item_feat_diff = set(self.item_feature_names) -\\\n",
    "                             set(item_feat.columns)\n",
    "\n",
    "            if len(item_feat_diff):\n",
    "                raise ValueError('Missing item features: {}'\n",
    "                                 .format(item_feat_diff))\n",
    "                \n",
    "        \n",
    "    @cachedmethod(cache=operator.attrgetter('_item_cache'),\n",
    "                  key=lambda _, __, item_ids: hashkey(item_ids))\n",
    "    def get_item_data(self, item_features, item_ids):\n",
    "        \"\"\"Return item data.\n",
    "        This creates the item feature csr and corresponding item names and\n",
    "        numerical ids. Caches result in case same items are requested again.\n",
    "        \"\"\"\n",
    "        item_ids = np.asarray(list(item_ids))\n",
    "        if item_features is not None:\n",
    "            assert item_features.shape[0] >= len(item_ids)\n",
    "            assert set(item_ids).issubset(set(item_features.index))\n",
    "            iid_map = pd.Series(np.arange(len(item_features)),\n",
    "                                index=item_features.index)\n",
    "        else:\n",
    "            iid_map = self.iid_map\n",
    "        iid_map = iid_map.reindex(item_ids)\n",
    "        return self._construct_item_features(item_features, item_ids), \\\n",
    "            iid_map.values,\\\n",
    "            iid_map.index\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_online(self, user_id, item_ids, item_features=None,\n",
    "                       user_features=None, num_threads=1, use_baseline=False):\n",
    "        self._check_missing_features(item_features, user_features)\n",
    "\n",
    "        if item_ids is not None:\n",
    "            if isinstance(item_ids, pd.Index):\n",
    "                item_ids = item_ids.tolist()\n",
    "            item_names = tuple(item_ids)\n",
    "        else:\n",
    "            item_names = tuple(self.iid_map.index.tolist())\n",
    "\n",
    "        item_feat_csr, num_item_ids, item_labels = \\\n",
    "            self.get_item_data(item_features, item_names)\n",
    "        try:\n",
    "            user_feat_csr = self._construct_user_features(user_id,\n",
    "                                                          user_features)\n",
    "        except KeyError:\n",
    "            if use_baseline:\n",
    "                return self.baseline\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        pred = super().predict(0, num_item_ids,\n",
    "                               item_feat_csr, user_feat_csr,\n",
    "                               num_threads)\n",
    "\n",
    "        pred = pd.Series(pred, index=item_labels)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _construct_item_features(self, item_features, item_ids):\n",
    "        \"\"\"Create item features during predict.\"\"\"\n",
    "        # align feature names\n",
    "        if self.indicator_setting in ['both', 'items']:\n",
    "            item_indicator = sp.SparseFrame(self._item_indicator,\n",
    "                                            index=self.iid_map.index)\n",
    "            item_indicator = item_indicator.reindex(item_ids).data\n",
    "        else:\n",
    "            item_indicator = None\n",
    "\n",
    "        if self.item_feature_names is None:\n",
    "            return item_indicator\n",
    "\n",
    "        item_feat_csr = item_features\\\n",
    "            .loc[:, self.item_feature_names]\\\n",
    "            .reindex(item_ids, axis=0)\\\n",
    "            .data\n",
    "        if item_indicator is not None:\n",
    "            item_feat_csr = sparse.hstack([item_feat_csr,\n",
    "                                           item_indicator])\n",
    "        return item_feat_csr\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        \"\"\"Support unpickling older versions of this class.\"\"\"\n",
    "        if 'identity_matrix' in state:\n",
    "            state['indicator_setting'] = state['identity_matrix']\n",
    "        self.__dict__ = state\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _construct_user_features(self, user_id, user_features):\n",
    "        \"\"\"Create user features for a single user.\"\"\"\n",
    "        # retrieve numerical user ids\n",
    "        # abort and return baseline recommendations if user is not known\n",
    "        # and no user features are passed\n",
    "        user_known = True\n",
    "        try:\n",
    "            num_user_id = self.uid_map.loc[user_id]\n",
    "        except KeyError:\n",
    "            # Case we have no features nor the user was known we abort.\n",
    "            if user_features is None:\n",
    "                raise\n",
    "            user_known = False\n",
    "            num_user_id = 0\n",
    "\n",
    "        if user_features is not None:\n",
    "            if self.user_feature_names is None:\n",
    "                raise ValueError('Model was trained without user features. '\n",
    "                                 'But received user features for prediction.')\n",
    "\n",
    "            user_feat_csr = user_features.loc[:, self.user_feature_names].data\n",
    "\n",
    "            if user_feat_csr.shape[0] > 1:\n",
    "                raise ValueError(\n",
    "                    'Received user feature matrix with more than 1 row.')\n",
    "        else:\n",
    "            user_feat_csr = None\n",
    "            if self.user_feature_names is not None and \\\n",
    "                            self.indicator_setting in [False, 'users']:\n",
    "                raise ValueError(\"Need user features as used \"\n",
    "                                 \"during training: {}\"\n",
    "                                 .format(self.user_feature_names))\n",
    "\n",
    "        if self.indicator_setting in ['users', 'both']:\n",
    "            # if no user_features were used during training\n",
    "            # no need to handle further cases just use indicator row.\n",
    "            if self.user_feature_names is None:\n",
    "                user_feat_csr = self._user_indicator[num_user_id]\n",
    "            # Append identity matrix only if user is known from training,\n",
    "            # features have been passed and the identity_matrix flag is set.\n",
    "            elif user_feat_csr is not None and user_known:\n",
    "                user_feat_csr = self.append_user_identity_row(user_feat_csr,\n",
    "                                                              num_user_id)\n",
    "            elif user_feat_csr is None and user_known:\n",
    "                empty_features = sparse.csr_matrix(\n",
    "                    (1, len(self.user_feature_names)))\n",
    "                user_feat_csr = self.append_user_identity_row(empty_features,\n",
    "                                                              num_user_id)\n",
    "            elif user_features is not None and not user_known:\n",
    "                user_feat_csr = self.append_user_identity_row(\n",
    "                    user_feat_csr, -1)\n",
    "        return user_feat_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
